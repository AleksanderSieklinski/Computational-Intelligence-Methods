{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę pobrać plik medicine.txt, zawierający wyniki analizy nowego leku. W dwóch pierwszych kolumnach znajduje się stężenie dwóch składników w próbce krwi, w trzeciej - informacja o tym, czy lek zadziałał. Dane nie są znormalizowane. Proszę znormalizować dane, podzielić je na zbiór uczący i testujący w proporcjach 80-20 (należy pamiętać o proporcjach klas), zaproponować wielowarstwową sieć neuronową i zbadać jej skuteczność dla różnych ilości warstw i neuronów w tych warstwach. Proszę narysować w jaki sposób sieć dokonała podziału w zbiorze dla kilku sieci (zarówno tych z dobrymi, jak i złymi wynikami) oraz jak wygląda poprawny podział zbioru. Proszę również przedstawić wyniki dla 5-8 różnych struktur sieci, wraz z oceną, która z nich najlepiej poradziła sobie z zadaniem klasyfikacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('medicine.txt', sep=',')\n",
    "scaler = StandardScaler()\n",
    "df[['Presence 1', 'Presence 2']] = scaler.fit_transform(df[['Presence 1', 'Presence 2']])\n",
    "X = df[['Presence 1', 'Presence 2']]\n",
    "y = df['Was medicine effective?']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=1)\n",
    "configs = [(10,), (20,), (10, 10), (20, 20), (10, 10, 10), (20, 20, 20), (10, 10, 10, 10), (20, 20, 20, 20), (20, 20, 20, 20, 20)]\n",
    "for config in configs:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=config, max_iter=1000, random_state=1)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    predictions = mlp.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Configuration: {config}, Accuracy: {accuracy * 100:.2f}%\")\n",
    "    x_min, x_max = X['Presence 1'].min() - .5, X['Presence 1'].max() + .5\n",
    "    y_min, y_max = X['Presence 2'].min() - .5, X['Presence 2'].max() + .5\n",
    "    h = .02\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n",
    "    plt.scatter(X['Presence 1'], X['Presence 2'], c=y, cmap=plt.cm.Spectral)\n",
    "    plt.title(f'Neural Network with configuration {config}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "Dzięki normalizacji, wszystkie cechy mają tę samą skalę, co ułatwia proces uczenia sieci neuronowej.\n",
    "Liczba warstw i neuronów w sieci neuronowej ma wpływ na jej skuteczność. W tym przypadku, sieci z większą liczbą warstw i neuronów osiągały wyższą skuteczność. Najlepszą skuteczność osiągnęła sieć z konfiguracją (20, 20, 20, 20).\n",
    "Sieci z większą liczbą warstw i neuronów były w stanie dokonać bardziej skomplikowanego podziału, co prawdopodobnie przyczyniło się do ich wyższej skuteczności."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę pobrać zbiór ręcznie pisanych cyfr z https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits (można to zrobić funkcją datasets.load_digits() w sklearnie). Proszę sprawdzić skuteczność klasyfikacji na tym zbiorze za pomocą wielowarstwowej sieci neuronowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,50), max_iter=1000, random_state=1)\n",
    "mlp.fit(X_train, y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "Wynik dokładności bliski 100% wskazuje, że model praktycznie idealnie klasyfikuje cyfry na podstawie danych wejściowych. Model prawidłowo nauczył się wzorców w danych treningowych i skutecznie za ich pomocą klasyfikuje dane testowe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę sprawdzić, jak zmieni się poprawność klasyfikacji na zbiorze ręcznie pisanych cyfr dla różnych architektur sieci, funkcji aktywacji, ilości epok uczenia i algorytmów uczenia. Proszę zbadać wpływ współczynnika uczenia (learning_rate) podczas używania algorytmu SGD. Dla najciekawszych przykładów proszę wypisać macierze pomyłek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.2, random_state=42)\n",
    "parameters = [\n",
    "    {'hidden_layer_sizes': (100,), 'solver': 'adam', 'max_iter': 1000},\n",
    "    {'hidden_layer_sizes': (50,50), 'solver': 'sgd', 'max_iter': 1000, 'learning_rate_init': 0.01},\n",
    "    {'hidden_layer_sizes': (30,30,30), 'solver': 'sgd', 'max_iter': 1000, 'learning_rate_init': 0.1},\n",
    "    {'hidden_layer_sizes': (10,10,10,10), 'solver': 'adam', 'max_iter': 1000, 'learning_rate_init': 0.001},\n",
    "    {'hidden_layer_sizes': (10,10,10,10), 'solver': 'adam', 'max_iter': 10000, 'learning_rate_init': 0.0001}\n",
    "]\n",
    "for params in parameters:\n",
    "    mlp = MLPClassifier(**params, random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    predictions = mlp.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Parameters: {params}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "Dokładność klasyfikacji ręcznie pisanych cyfr zwiększa się wraz ze zwiększaniem liczby warstw i neuronów w sieci neuronowej. Najlepsze wyniki uzyskano dla konfiguracji (100,).\n",
    "Wpływ współczynnika uczenia (learning_rate) podczas używania algorytmu SGD jest również widoczny. Dla learning_rate = 0.0001 i learning_rate = 0.1, dokładność wynosiła odpowiednio 93.33% i 9.72%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę pobrać zbiór yeast z UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Yeast). Proszę we własnym zakresie dokonać wstępnej analizy i przygotowania tego zbioru (uwaga, wymagana jest zamiana etykiet tekstowych w ostatniej kolumnie na liczbowe - można je zamienić ręcznie albo przy użyciu takich narzędzi jak https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html, należy jednak pamiętać, że nie musi on ułożyć tych etykiet po kolei). Warto zauważyć, że liczności różnych klas wewnątrz zbioru są _bardzo_ nierówne. Proszę spróbować osiągnąć jak najlepsze wyniki i narysować dla nich macierz pomyłek (dla zbioru uczącego i testującego). Czy trafność na poziomie 0.5 dla takiego zbioru jest dobra? Mogą państwo zbadać też czas wykonywania funkcji fit dla różnych konfiguracji sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/yeast/yeast.data\"\n",
    "names = ['Sequence Name', 'mcg', 'gvh', 'alm', 'mit', 'erl', 'pox', 'vac', 'nuc', 'class']\n",
    "df = pd.read_csv(url, names=names, delim_whitespace=True)\n",
    "print(df.describe())\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['class'] = le.fit_transform(df['class'])\n",
    "X = df.drop(['Sequence Name', 'class'], axis=1)\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=3000, random_state=1)\n",
    "start_time = time.time()\n",
    "mlp.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "predictions = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Training time: {end_time - start_time:.2f}s\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"Confusion matrix (train set):\")\n",
    "print(confusion_matrix(y_train, mlp.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wnioski:**\n",
    "Analizując macierze pomyłek, widzimy, że model ma trudności z niektórymi klasami. Na przykład, dla klasy oznaczonej jako '0', model często mylnie klasyfikuje ją jako '7'.\n",
    "Nierównomierność liczności różnych klas w zbiorze danych jest prawdopodobnie jednym z czynników wpływających na te trudności. \n",
    "Model osiąga lepsze wyniki na zbiorze treningowym niż na zbiorze testowym. Może to wskazywać na overfitting, czyli zbyt mocne dopasowanie modelu do danych treningowych kosztem jego zdolności do generalizacji na nowe dane."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
